---
title: "Research Report: PROJECT-TITLE"
subtitle: "Big Data Analytics, Group Examination: GROUPNAME"
author:
- Author1 (Student ID)
- Author2 (Student ID)
- Author3 (Student ID)
- Author4 (Student ID)

date: "15/10/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction (max. 500 words)

## Research Question(s)

## Data Source(s)

## Summary of Methods and Results



# Data Collection and Data Storage (max. 500 words, not including code and code comments)


<!-- Describe how you approach the data collection procedure. In your research setting, what were the challenges regarding collecting the raw data. How did you solve these challenges? How do you store the raw data and why?  -->


```{r}

# Either paste your data collection code here or refer to it via source("code/mycode.R")

```



# Data Cleaning and Preparation (max. 500 words, not including code and code comments)

<!-- Describe the challenges related to cleaning/filtering your raw data in order to prepare an analytic data set. What were the bottle necks (which tasks and which hardware resources)? How did you speed up/improve the data cleaning procedure for large amounts of data? Which tools/techniques did you use and how do these tools/techniques work? Provide visualizations or statistics to summarize the cleaned dataset.  -->


```{r}

# Either paste your data preparation code here or refer to it via source("code/mycode.R")

```



#  Data Analysis and Data Visualization (max. 2 exhibits [figures/tables] and, not including code and code comments)

<!-- Explain how you analyzed the data (which method(s) were used and why?). Then explain what the challenges were in implementing these analyses, given the large amount of data. Finally, explain which tools/techniques you have used in order to tackle these challenges. Make sure to point out why you have chosen these tools/techniques and how they helped to address the problems.   -->


```{r}

# Either paste your data analysis code here or refer to it via source("code/mycode.R")

```


# Results and Discussion (max. 5 exhibits [figures/tables] and 800 words, not including code, comments, and figure captions)



<!-- Present the outcomes of the analysis in relation to the research questions. Use up to 5 exhibits (tables and figures) to support the interpretation of the results. Right below each table/figure, add table/figure-notes that describe what the reader sees in the corresponding table/figure. (Hint: have a look at empirical papers in the top Econ outlets like AER, QJE, Econometrica, etc. to get a feeling for how Economists write such notes.). Discuss any limitations encountered during the analysis, such as data quality, computational limitations, or biases in the dataset. Propose improvements or additional research directions that could further explore the dataset or extend the current analysis -->


```{r}

# Refer to the script(s) that generate the figures/tables via source("code/mycode.R") here

```




# Scaling and Cloud Deployment (max. 800 words, not including code and code comments)


<!-- Almost done! In this last section, critically evaluate the performance and the limits of the models or techniques used. Suppose you have to re-run your data pipeline with substantially more data. Further suppose that you have access to cloud resources to scale up/scale out the different components of your pipeline. Briefly describe which cloud solutions you would use for which part of your analysis and explain why. Note: as in the explanations above, this part is also very project-specific. Some cloud solutions probably make sense for some projects but would be overkill in other projects, etc.  -->


